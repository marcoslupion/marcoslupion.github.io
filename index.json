[{"authors":null,"categories":null,"content":"Marcos Lupi√≥n Lorente is a PhD student in the \u0026ldquo;Supercomputing and Algorithms\u0026rdquo; research group at the University of Almeria. His main interests are the Internet of Things (IoT) and the creation of solutions that improve the lives of elderly, disabled or dependent people.\n","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Marcos Lupi√≥n Lorente is a PhD student in the \u0026ldquo;Supercomputing and Algorithms\u0026rdquo; research group at the University of Almeria. His main interests are the Internet of Things (IoT) and the creation of solutions that improve the lives of elderly, disabled or dependent people.","tags":null,"title":"Marcos Lupi√≥n Lorente","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://marcoslupion.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["M. Lupi√≥n","N.C. Cruz","B. Paechter","P.M. Ortigosa"],"categories":null,"content":"","date":1659052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659052800,"objectID":"56060e6ecd481d4f62eedacba2265bf7","permalink":"https://marcoslupion.github.io/publication/9_europt22/","publishdate":"2022-07-29T00:00:00Z","relpermalink":"/publication/9_europt22/","section":"publication","summary":"","tags":null,"title":"On the use of teaching-learning based optimization to train neural networks","type":"publication"},{"authors":["M. Lupi√≥n","N.C. Cruz","P.M. Ortigosa"],"categories":null,"content":"","date":1658102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658102400,"objectID":"4df4bf715f82c68180a1152b6d8f3b0f","permalink":"https://marcoslupion.github.io/publication/7_ola22/","publishdate":"2022-07-18T00:00:00Z","relpermalink":"/publication/7_ola22/","section":"publication","summary":"","tags":["Artificial intelligence","Neural network training","Meta-heuristics","Teaching-Learning-based optimization"],"title":"Training large convolutional neural networks through population-based meta-heuristics","type":"publication"},{"authors":["M. Lupi√≥n","J.F. Sanjuan","J. Medina-Quero","P.M. Ortigosa"],"categories":null,"content":"","date":1657670400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657670400,"objectID":"4e774523a37c30df6ef44488147a59dc","permalink":"https://marcoslupion.github.io/publication/8_isami22/","publishdate":"2022-07-13T00:00:00Z","relpermalink":"/publication/8_isami22/","section":"publication","summary":"Epilepsy is one of the most common chronic brain diseases, but with the proper medication, patients enjoy everyday life. New trends in Internet of Things approaches are now introduced to detect seizures in users with epilepsy to adjust treatments, reducing mortality rates due to the fatal consequences they develop. Wearable devices on the market can detect motor seizures thanks to their built-in acceleration sensors. However, the limitations of this type of device are the short battery life, a non-ergonomic design, and the high price. In this work, we propose a low-cost system that allows the monitoring of users in residential centers using a wearable device equipped with an acceleration sensor. The epileptic seizure detection algorithm has been built following federated machine learning, creating a general model for all possible users from the models learned in each residential center. Based on the first results, the system has more than 60 hours of autonomy, obtaining favorable detection rates in the first simulations. In this case, the information of each user is kept in the local environment, maintaining privacy.","tags":["Epilepsy Seizure Detection","Federated Machine Learning","Fog Computing","Low Cost Devices"],"title":" Epilepsy seizure detection using low-cost IoT devices and a federated machine learning algorithm","type":"publication"},{"authors":["M. Lupi√≥n","N.C. Cruz","B. Paechter","P.M. Ortigosa"],"categories":null,"content":"","date":1657497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657497600,"objectID":"e59b98090e59167436d28f620d886400","permalink":"https://marcoslupion.github.io/publication/6_mic22/","publishdate":"2022-07-11T00:00:00Z","relpermalink":"/publication/6_mic22/","section":"publication","summary":"Neural networks stand out in Artificial Intelligence for their capacity of being applied to multiple challenging tasks such as image classification. However, designing a neural network to address a particular problem is also a demanding task that requires expertise and time-consuming trial-and-error stages. The design of methods to automate the designing of neural networks define a research field that generally relies on different optimization algorithms, such as population meta-heuristics. This work studies utilizing Teaching-Learning-based Optimization (TLBO), which had not been used before for this purpose up to the authors' knowledge. It is widespread and does not have specific parameters. Besides, it would be compatible with deep neural network design, i.e., architectures with many layers, due to its conception as a large-scale optimizer. A new encoding scheme has been proposed to make this continuous optimizer compatible with neural network design. This method, which is of general application, i.e., not linked to TLBO, can represent different network architectures with a plain vector of real values. A compatible objective function that links the optimizer and the representation of solutions has also been developed. The performance of this framework has been studied by addressing the design of an image classification neural network based on the CIFAR-10 dataset. The achieved result outperforms the initial solutions designed by humans after letting them evolve.","tags":["Artificial intelligence","Neural network architecture optimization","Meta-heuristics","Teaching-Learning-based optimization"],"title":"On optimizing the structure of neural networks through a compact codification of their architecture","type":"publication"},{"authors":["M. Lupi√≥n","N.C. Cruz","P.M. Ortigosa"],"categories":null,"content":"","date":1656806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656806400,"objectID":"b50ebaf6e95592bb26e8c5e2284ecd33","permalink":"https://marcoslupion.github.io/publication/5_cmmse22/","publishdate":"2022-07-03T00:00:00Z","relpermalink":"/publication/5_cmmse22/","section":"publication","summary":"Neural Architecture Search (NAS) is a research field that studies how to automate the creation of optimal neural networks and how to reduce the dedication of human experts. Current results in the literature demonstrate that it is even possible to outperform designs by humans. In this field, the use of meta-heuristic global optimization algorithms is widespread. However, some of them, such as Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO), require the user to tune several parameters significantly affecting their performance. In this work, we propose using the Teaching-Learning-Based Optimization (TLBO) algorithm, which has been applied to numerous different problems. It looks for the optimal neural network architecture by simulating the learning process in a classroom with a teacher and several students. This algorithm has few parameters and supports high-dimensional problems. In addition, we present an encoding scheme that allows representing neural network architectures as vectors of real numbers. It is inspired by the transformation of N-Dimensional vectors to 1-Dimensional ones, which is frequent in high-performance computing. The target problem is challenging and computationally demanding. Thus, the proposed implementation assesses the candidate neural networks in parallel. Infeasible ones can be evaluated on CPUs. However, feasible neural networks, which must be trained with backpropagation and ultimately evaluated, should run on GPU since it is a more convenient computing platform in this context. The solution class is unknown in advance, so it is not advisable to distribute the load statically. Moreover, even feasible solutions running on GPUs might take different times to be evaluated because their complexities differ. Therefore, we propose the following two-phase evaluation approach i) a first evaluation on CPU using OpenMP to differentiate individuals with viable and non-viable architectures, and ii) a subsequent evaluation of GPU individuals using an oracle programmed in OpenMPI that dynamically distributes the load among GPUs. As preliminary results, the proposed method obtains neural network architectures that outperform known structures for the CIFAR10 dataset. Moreover, with the two-phase evaluation, a speedup of 4.2 is achieved over the sequential version, being the theoretical limit equal to 4.39 for the considered platform.","tags":["neural architecture search","multi-gpu","parallel computing"],"title":"On analyzing a parallel multi-GPU framework for the architecture optimization of neural networks","type":"publication"},{"authors":["A Polo-Rodr√≠guez","M. Lupi√≥n","P.M. Ortigosa","J. Medina-Quero"],"categories":null,"content":"","date":1656288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656288000,"objectID":"1d737ed53e1570392002b869f33e4de2","permalink":"https://marcoslupion.github.io/publication/4_iwbbio22/","publishdate":"2022-06-27T00:00:00Z","relpermalink":"/publication/4_iwbbio22/","section":"publication","summary":"In this work, we propose the use of thermal vision sensors to estimate the frontal body landmarks of an inhabitant. The use of thermal sensors is being promoted to collect human patterns while protecting inhabitants' privacy in smart environments. On the other hand, deep learning approaches have provided encouraging results in estimating body, hand and facial landmarks. Here, we present a residual neural network which produces body landmarks from images collected by a low cost thermal sensor. In order to solve the problems of capturing and labeling data, which hinder learning in deep learning models, we propose an auto-labeling approach with dual visible-spectrum and thermal cameras, including the recognition of keypoints by the OpenPose model.  A case study developed with four inhabitants in different poses shows encouraging results.","tags":["thermal sensor","residual neural network","body landmark"],"title":"Estimating frontal body-landmark from thermal sensors using Residual Neural Networks","type":"publication"},{"authors":["Marcos Lupi√≥n","Aurora Polo-Rodr√≠guez","Juan F. Sanjuan","Pilar M. Ortigosa"],"categories":null,"content":"","date":1651795200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651795200,"objectID":"55ac6d9e94bcbc343a610569feec387b","permalink":"https://marcoslupion.github.io/publication/eswa/","publishdate":"2022-05-06T00:00:00Z","relpermalink":"/publication/eswa/","section":"publication","summary":"One of the main objectives of smart homes is to facilitate daily life by increasing user comfort, with the potential to play a key role in revolutionizing healthcare for the elderly, the disabled and people with functional limitations. To achieve this end, smart homes will have to be able to distinguish the identity of users, their location and the activities they are performing, while also being implemented in a non-invasive way that protects the privacy of these users. Computer vision is one of the main technologies included in smart homes. However, there are drawbacks to traditional cameras, given their dependence on light and privacy-related concerns. Thermal cameras provide a solution, as they operate regardless of light conditions (e.g. at night) while respecting users‚Äô privacy. In this work, image reconstruction and identification of inhabitants from facial images collected by low-resolution thermal sensors has been carried out by using Conditional Generative Adversarial Neural Networks (CGANs). The system has been implemented through an IoT device with raspberry Pi and dual-vision thermal and visible-spectrum sensors installed in a real smart home to automatically collect paired visible-spectrum and thermal images. Thus, different configurations of CGANs have been implemented and analyzed to achieve the following outcomes; (1) inhabitant identification (normal and masked face) with enhanced user privacy and (2) transfer from thermal to color images in the visible spectrum. Results show that the proposed CGAN achieves a recognition rate of 95% and 94% for uncovered and masked faces. This enables user identification without registering accurate facial expressions in the color image reconstruction, protecting user privacy. Furthermore, the developed system outperformed similar approaches using low-resolution datasets and has demonstrated that the accuracy of image reconstruction depends on the resolution of the input visible-spectrum images. In addition, a contribution to high-performance computing has been made by designing a CGAN that runs efficiently on multiple GPUs, achieving increased performance and response speed of the network, as well as applicability to larger problems.","tags":["Generative Adversarial Networks (GANs)","Image translation","Thermal image","Face recognition","Privacy"],"title":"On the limits of Conditional Generative Adversarial Neural Networks to reconstruct the identification of inhabitants from IoT low-resolution thermal sensors","type":"publication"},{"authors":["Marcos Lupi√≥n","Juan F. Sanjuan","Pilar M. Ortigosa"],"categories":null,"content":"","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"f4d24592612d62e8e6ef4016d0a3be8c","permalink":"https://marcoslupion.github.io/publication/jos/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/publication/jos/","section":"publication","summary":"Generative adversarial networks are gaining importance in problems such as image conversion, cross-domain translation and fast styling. However, the training of these networks remains unclear because it often results in unexpected behavior caused by non-convergence, model collapse or overly long training, causing the training task to have to be supervised by the user and vary with each dataset. To increase the speed of training in Pix2Pix (image-to-image translation) networks, this work incorporates multi-GPU training using mixed precision, along with optimizations in the GPU image input process. In addition, in order to make the training unsupervised and to terminate it when the best transformations are performed, an early stopping method using the peak signal noise ratio (PSNR) metric is proposed.","tags":["Generative adversarial networks","Pix2Pix","Multi-GPU","Mixed precision","Early stopping"],"title":"Using a Multi-GPU node to accelerate the training of Pix2Pix neural networks","type":"publication"},{"authors":["M. Lupion","J. Medina-Quero","J.F. Sanjuan","J.L. Redondo","P. M. Ortigosa"],"categories":null,"content":"","date":1631232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631232000,"objectID":"4be7041e3d72fd1ec7f5a47807e01cbe","permalink":"https://marcoslupion.github.io/publication/2_sarteco21/","publishdate":"2021-09-10T00:00:00Z","relpermalink":"/publication/2_sarteco21/","section":"publication","summary":"El reconocimiento de actividades (AR) es un campo de investigaci√≥n actual centrado en la detecci√≥n de acciones y comportamientos humanos en entornos inteligentes. En este trabajo, se presenta la plataforma de reconocimiento de actividades en tiempo real DOLARS, donde se eval√∫an y clasifican datos de sensores multimodales, incluyendo sensores binarios, wearable y de localizaci√≥n. Diferentes descriptores y m√©tricas de los datos de sensores multimodales se integran en un vector de caracter√≠sticas com√∫n que se computa con un enfoque de ventanas deslizantes en condiciones de tiempo real. DOLARS proporciona una arquitectura distribuida en la que (i) las etapas para procesar los datos se despliegan en nodos distribuidos, (ii) los m√≥dulos de cach√© temporal calculan las m√©tricas que agregan los datos de los sensores para calcular el vector de caracter√≠sticas de forma eficiente; (iii) se integran modelos de publicaci√≥n-suscripci√≥n tanto para difundir los datos de los sensores como para orquestar los nodos (comunicaci√≥n y replicaci√≥n) con el objetivo de reconocer las actividades, y (iv) se utilizan algoritmos de aprendizaje autom√°tico para clasificar y reconocer las actividades. En este trabajo se presenta un caso de estudio sobre reconocimiento de actividades diarias desarrollado en el Smart Lab de la Universidad de Almer√≠a (UAL). Los resultados presentan un rendimiento excelente en el reconocimiento de secuencias de actividades y muestran la necesidad de las arquitecturas distribuidas para lograr el reconocimiento en tiempo real.","tags":["Reconocimiento de actividades","tiempo real","sensores","smarthome","sistema distribuido","ventanas deslizantes"],"title":"Sistema distribuido de reconocimiento de actividades en tiempo real, DOLARS","type":"publication"},{"authors":["M. Lupi√≥n","Juan F. Sanjuan","P.M. Ortigosa"],"categories":null,"content":"","date":1626912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626912000,"objectID":"a7ce36655a08c8f44045b7d4cad7e4cb","permalink":"https://marcoslupion.github.io/publication/3_cmmse21/","publishdate":"2021-07-22T00:00:00Z","relpermalink":"/publication/3_cmmse21/","section":"publication","summary":"Generative Adversarial Networks are gaining importance in problems such as image-to-image, cross-domain translation and fast stylization. However, the training of these networks remains unclear because it often produces non-expected behaviour caused by non-convergence, model collapse or a training too long. Pix2pix are a kind of Generative Adversarial Networks that carry out image-to-image translation between two domains. In the original paper, in datasets which do not exceed 2,000 images the batch size is set to 1, obtaining good results with a not very high amount of training time. However, if datasets with a larger number of images are incorporated, a maximum batch size of 4 is used, causing the training to be slow. Therefore, it is necessary to optimize the training by the use of high performance computing resources in order to be successful when training with huge databases. In the literature there are some approaches which aim to exploit the hardware platform where these algorithms are trained; in the most of cases, the GPU is chosen due to its high computing performance. In several approaches, some a multi-worker systems are implemented to adapt the batch size and learning rate parameters to optimize the use of GPUs in convolutional neural networks. However, no references of how efficiently train generative generative adversarial neural networks such as pix2pix are found. In this paper, we are going to focus on this problem and propose a new approach to accelerate the pix2pix problem by using modern MultiGPU architectures in Tensorflow. The new paralel model is described in detail so it can be used as guide for users. Some of the contributions made in the MultiGPU model are (a) the introduction of an optimized input pipeline that reduces the cost associated with loading data into the GPUs. (b) The introduction of the half-precision computation  to reduce the memory used in training. (c) The definition of new loss functions to correctly compute the neural networks losses in the MultiGPU node. These loss functions are different from the SingleGPU execution, as the amount of work is divided into two or more GPUs. (d) The definition of an early stopping method which stops when training completes before it gets worse. This method takes into account the distance between generator and discriminator loss in validation time.","tags":["Generative Adversarial Networks","pix2pix","MultiGPU","mixed-precision","early-stopping"],"title":"Accelerating Pix2Pix training using a multi-gpu node","type":"publication"},{"authors":["Marcos Lupi√≥n","Javier Medina-Quero","Juan F. Sanjuan","Pilar M. Ortigosa"],"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610064000,"objectID":"e4d6fd78aedc62fad0771e8bf2047732","permalink":"https://marcoslupion.github.io/publication/dolars/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/publication/dolars/","section":"publication","summary":"Activity Recognition (AR) is an active research topic focused on detecting human actions and behaviours in smart environments. In this work, we present the on-line activity recognition platform DOLARS (Distributed On-line Activity Recognition System) where data from heterogeneous sensors are evaluated in real time, including binary, wearable and location sensors. Different descriptors and metrics from the heterogeneous sensor data are integrated in a common feature vector whose extraction is developed by a sliding window approach under real-time conditions. DOLARS provides a distributed architecture where (i) stages for processing data in AR are deployed in distributed nodes, (ii) temporal cache modules compute metrics which aggregate sensor data for computing feature vectors in an efficient way; (iii) publish-subscribe models are integrated both to spread data from sensors and orchestrate the nodes (communication and replication) for computing AR and (iv) machine learning algorithms are used to classify and recognize the activities. A successful case study of daily activities recognition developed in the Smart Lab of The University of Almer√≠a (UAL) is presented in this paper. Results present an encouraging performance in recognition of sequences of activities and show the need for distributed architectures to achieve real time recognition.","tags":["activity recognition","real-time","smart home","sliding windows","distributed system"],"title":"DOLARS, a Distributed On-Line Activity Recognition System by Means of Heterogeneous Sensors in Real-Life Deployments‚ÄîA Case Study in the Smart Lab of The University of Almer√≠a","type":"publication"},{"authors":["Marcos Lupi√≥n Lorente","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://marcoslupion.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["M. Lupi√≥n","J. L. Redondo","J. F. Sanjuan","P. M. Ortigosa"],"categories":null,"content":"","date":1599696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599696000,"objectID":"4503f851344bad3806098482cc03892c","permalink":"https://marcoslupion.github.io/publication/1_isami20/","publishdate":"2020-09-10T00:00:00Z","relpermalink":"/publication/1_isami20/","section":"publication","summary":"Currently, most smart homes are aimed at user comfort or even energy efficiency. However, there are many cases in which Ambient Assisted Living is being used, to control the health of the elderly people, or people with disabilities. In this paper, a proposal for an IoT system for activity recognition in a smart home will be shown. Specifically, various low-cost sensors are incorporated into a home that send data to the cloud. In addition, an activity recognition algorithm has been included to classify the information from the sensors and to determine which activity has been carried out. Results are also displayed in a web system, allowing the user to validate them or correct them. This web system allows the visualization of the data generated by the sensors of the smart home and help to easily monitor the activities carried out, and to alert to the doctors or the user‚Äôs family when bad habits or any problem in the behaviour are detected.","tags":["Ambient Assisted Living","Activity recognition","Machine learning algorithm"],"title":"Deployment of an IoT Platform for Activity Recognition at the UAL‚Äôs Smart Home","type":"publication"},{"authors":["M. Lupi√≥n","J. M. Quero","P. M. Ortigosa"],"categories":null,"content":"","date":1563148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563148800,"objectID":"cc38f7494a54acfdaab99205d344a4c3","permalink":"https://marcoslupion.github.io/publication/tfm/","publishdate":"2019-07-15T00:00:00Z","relpermalink":"/publication/tfm/","section":"publication","summary":"","tags":["Final Master Project","Activity Recognition","Realtime","Multimodal sensors"],"title":"Detecci√≥n de actividades en tiempo real con sensores multimodales en una Smart Home","type":"publication"},{"authors":["M. Lupi√≥n","P. M. Ortigosa"],"categories":null,"content":"","date":1562112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562112000,"objectID":"804c18c6b61a32733032b66144b2d5a7","permalink":"https://marcoslupion.github.io/publication/complemento/","publishdate":"2019-07-03T00:00:00Z","relpermalink":"/publication/complemento/","section":"publication","summary":"","tags":["Final Degree Project","Activity Recognition","Machine Learning"],"title":"Algoritmo de reconocimiento de actividades en un ambiente inteligente","type":"publication"},{"authors":["M. Lupi√≥n","P. M. Ortigosa"],"categories":null,"content":"","date":1562112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562112000,"objectID":"e68f632a822bbd01edcd24dd5dba49e6","permalink":"https://marcoslupion.github.io/publication/tfg/","publishdate":"2019-07-03T00:00:00Z","relpermalink":"/publication/tfg/","section":"publication","summary":"","tags":["Final Degree Project","Internet of Things","Sensors","Activity Recognition"],"title":"Implantaci√≥n de un ambiente inteligente","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://marcoslupion.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://marcoslupion.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]